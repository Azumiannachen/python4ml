{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cycle GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on paper [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/abs/1703.10593)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resblock(nn.Module):\n",
    "    def __init__(self,out_,k_):\n",
    "        super(resblock,self).__init__()\n",
    "        \n",
    "        self.out_ = out_\n",
    "        self.k_ = k_\n",
    "        \n",
    "        self.padding = math.floor(self.k_/2)\n",
    "        self.conv1 = nn.Conv2d(self.out_,self.out_,self.k_,stride=2,padding=self.padding,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.out_)\n",
    "        self.leaky1 = nn.LeakyReLU()\n",
    "        self.upconv = nn.Upsample(scale_factor=2)\n",
    "        self.bn2 = nn.BatchNorm2d(self.out_)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = x.clone()\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.leaky1(x)\n",
    "        \n",
    "        x = self.upconv(x)\n",
    "        x = self.bn2(x)\n",
    "        x = x + x1\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = resblock(256,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generative(nn.Module):\n",
    "    def __init__(self,fn_list,k_list = None):\n",
    "        super(generative,self).__init__()\n",
    "        self.fn_list = fn_list\n",
    "        if k_list == None:\n",
    "            self.k_list = [3]*(len(self.fn_list)-1)\n",
    "        else:\n",
    "            self.k_list = k_list\n",
    "        self.leaky = nn.LeakyReLU()\n",
    "        for i in range(len(self.fn_list)-1):\n",
    "            setattr(self,\"tran_%s\"%(i),nn.Conv2d(self.fn_list[i],\n",
    "                                                 self.fn_list[i+1],\n",
    "                                                 kernel_size = self.k_list[i],\n",
    "                                                 padding = self.k2pad(self.k_list[i]),\n",
    "                                                 bias = False))\n",
    "            setattr(self,\"bn_trans_%s\"%(i),nn.BatchNorm2d(self.fn_list[i+1]))\n",
    "            \n",
    "            setattr(self,\"resblock_%s\"%(i),resblock(self.fn_list[i+1],self.k_list[i]))\n",
    "            setattr(self,\"bn_res_%s\"%(i),nn.BatchNorm2d(self.fn_list[i+1]))\n",
    "            \n",
    "        self.conv_out = nn.Conv2d(self.fn_list[-1],3,1,bias=False)\n",
    "            \n",
    "    def k2pad(self,k):\n",
    "        return math.floor(k/2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        for i in range(len(self.fn_list)-1):\n",
    "            x = getattr(self,\"tran_%s\"%(i))(x)\n",
    "            x = getattr(self,\"bn_trans_%s\"%(i))(x)\n",
    "            x = self.leaky(x)\n",
    "            x = getattr(self,\"resblock_%s\"%(i))(x)\n",
    "            x = getattr(self,\"bn_res_%s\"%(i))(x)\n",
    "            x = self.leaky(x)\n",
    "        x = self.conv_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resblock_d(nn.Module):\n",
    "    def __init__(self,in_,out_,k_,downsample=True):\n",
    "        super(resblock_d,self).__init__()\n",
    "        \n",
    "        self.in_ = in_\n",
    "        self.out_ = out_\n",
    "        self.k_ = k_\n",
    "        self.downsample = downsample\n",
    "        \n",
    "        self.leaky = nn.LeakyReLU()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(self.in_,\n",
    "                               self.in_,\n",
    "                               kernel_size=self.k_,\n",
    "                               stride=1,\n",
    "                               padding=self.k2pad(self.k_),\n",
    "                               bias=False)\n",
    "        self.bn_1 = nn.BatchNorm2d(self.in_)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(self.in_,\n",
    "                               self.in_,\n",
    "                               kernel_size=self.k_,\n",
    "                               stride=1,\n",
    "                               padding=self.k2pad(self.k_),\n",
    "                               bias=False)\n",
    "        self.bn_2 = nn.BatchNorm2d(self.in_)\n",
    "        \n",
    "        if self.downsample:\n",
    "            self.out = nn.Conv2d(self.in_,self.out_,self.k_,\n",
    "                                 padding=self.k2pad(self.k_),stride=2,bias=False)\n",
    "            self.bn_out = nn.BatchNorm2d(self.out_)\n",
    "        \n",
    "    def k2pad(self,k):\n",
    "        return math.floor(k/2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x1 = x.clone()\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn_1(x)\n",
    "        x = self.leaky(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn_2(x)\n",
    "        x = self.leaky(x)\n",
    "        \n",
    "        x = x + x1\n",
    "        \n",
    "        if self.downsample:\n",
    "            x = self.out(x)\n",
    "            x = self.bn_out(x)\n",
    "            x = self.leaky(x)\n",
    "            \n",
    "        return x\n",
    "\n",
    "class discriminative(nn.Module):\n",
    "    def __init__(self,fn_list,k_list = None):\n",
    "        super(discriminative,self).__init__()\n",
    "        self.fn_list = fn_list\n",
    "        \n",
    "        if k_list == None:\n",
    "            self.k_list = [3]*(len(self.fn_list)-1)\n",
    "        else:\n",
    "            self.k_list = k_list\n",
    "            \n",
    "        self.conv_in = nn.Conv2d(3,self.fn_list[0],3,padding=1,bias=False)\n",
    "        self.bn_in = nn.BatchNorm2d(self.fn_list[0])\n",
    "        \n",
    "        for i in range(len(self.fn_list)-1):\n",
    "            setattr(self,\"res_%s\"%(i),resblock_d(self.fn_list[i],\n",
    "                                                 self.fn_list[i+1],\n",
    "                                                 k_ = self.k_list[i]))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv_in(x)\n",
    "        x = self.bn_in(x)\n",
    "        \n",
    "        for i in range(len(self.fn_list)-1):\n",
    "            x = getattr(self,\"res_%s\"%(i))(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = discriminative([64,64,64,128,128,256,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discriminative(\n",
       "  (conv_in): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn_in): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (res_0): resblock_d(\n",
       "    (leaky): LeakyReLU(negative_slope=0.01)\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (out): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn_out): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (res_1): resblock_d(\n",
       "    (leaky): LeakyReLU(negative_slope=0.01)\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (out): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn_out): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (res_2): resblock_d(\n",
       "    (leaky): LeakyReLU(negative_slope=0.01)\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (out): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn_out): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (res_3): resblock_d(\n",
       "    (leaky): LeakyReLU(negative_slope=0.01)\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (out): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn_out): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (res_4): resblock_d(\n",
       "    (leaky): LeakyReLU(negative_slope=0.01)\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (out): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn_out): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (res_5): resblock_d(\n",
       "    (leaky): LeakyReLU(negative_slope=0.01)\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (out): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn_out): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 4, 4])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D(torch.rand(2,3,256,256)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generative([3,128,128,128,256,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generative(\n",
       "  (leaky): LeakyReLU(negative_slope=0.01)\n",
       "  (tran_0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn_trans_0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (resblock_0): resblock(\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky1): LeakyReLU(negative_slope=0.01)\n",
       "    (upconv): Upsample(scale_factor=2, mode=nearest)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (bn_res_0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (tran_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn_trans_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (resblock_1): resblock(\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky1): LeakyReLU(negative_slope=0.01)\n",
       "    (upconv): Upsample(scale_factor=2, mode=nearest)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (bn_res_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (tran_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn_trans_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (resblock_2): resblock(\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky1): LeakyReLU(negative_slope=0.01)\n",
       "    (upconv): Upsample(scale_factor=2, mode=nearest)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (bn_res_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (tran_3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn_trans_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (resblock_3): resblock(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky1): LeakyReLU(negative_slope=0.01)\n",
       "    (upconv): Upsample(scale_factor=2, mode=nearest)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (bn_res_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (tran_4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn_trans_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (resblock_4): resblock(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leaky1): LeakyReLU(negative_slope=0.01)\n",
       "    (upconv): Upsample(scale_factor=2, mode=nearest)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (bn_res_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_out): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 160, 160])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G(torch.rand(2,3,160,160)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
